{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-odds ratio with an informative (and uninformative) Dirichlet prior (described in [Monroe et al. 2009, Fighting Words](http://languagelog.ldc.upenn.edu/myl/Monroe.pdf)) is a common method for finding distinctive terms in two datasets (see [Jurafsky et al. 2014](https://firstmonday.org/ojs/index.php/fm/article/view/4944/3863) for an example article that uses it to make an empirical argument). This method for finding distinguishing words combines a number of desirable properties:\n",
    "\n",
    "* it specifies an intuitive metric (the log-odds) for comparing word probabilities in two corpora\n",
    "* it incorporates prior information in the form of pseudocounts, which can either act as a smoothing factor (in the uninformative case) or incorporate real information about the expected frequency of words overall.\n",
    "* it accounts for variability of a frequency estimate by essentially converting the log-odds to a z-score.\n",
    "\n",
    "In this homework you will implement both of these ratios and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, operator, math, nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_tokenize(filename):\n",
    "    \n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        tokens=[]\n",
    "        # lowercase\n",
    "        for line in file:\n",
    "            data=line.rstrip().lower()\n",
    "            # This dataset is already tokenized, so we can split on whitespace\n",
    "            tokens.extend(data.split(\" \"))\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we'll use in this case comes from a sample of 1000 positive and 1000 negative movie reviews from the [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/).  The version of the data used in this homework has already been tokenized for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_tokens=read_and_tokenize(\"../data/negative.reviews.txt\")\n",
    "positive_tokens=read_and_tokenize(\"../data/positive.reviews.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.  Implement the log-odds ratio with an uninformative Dirichlet prior.  This value, $\\hat\\zeta_w^{(i-j)}$ for word $w$ reflecting the difference in usage between corpus $i$ and corpus $j$, is given by the following equation:\n",
    "\n",
    "$$\n",
    "\\hat\\zeta_w^{(i-j)}= {\\hat{d}_w^{(i-j)} \\over \\sqrt{\\sigma^2\\left(\\hat{d}_w^{(i-j)}\\right)}}\n",
    "$$\n",
    "\n",
    "Where: \n",
    "\n",
    "$$\n",
    "\\hat{d}_w^{(i-j)} = \\log \\left({y_w^i + \\alpha_w} \\over {n^i + \\alpha_0 - y_w^i - \\alpha_w}) \\right) -  \\log \\left({y_w^j + \\alpha_w} \\over {n^j + \\alpha_0 - y_w^j - \\alpha_w}) \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma^2\\left(\\hat{d}_w^{(i-j)}\\right) \\approx {1 \\over {y_w^i + \\alpha_w}} + {1 \\over {y_w^j + \\alpha_w} }\n",
    "$$\n",
    "\n",
    "And:\n",
    "\n",
    "* $y_w^i = $ count of word $w$ in corpus $i$ (likewise for $j$)\n",
    "* $\\alpha_w$ = 0.01\n",
    "* $V$ = size of vocabulary (number of distinct word types)\n",
    "* $\\alpha_0 = V * \\alpha_w$\n",
    "* $n^i = $ number of words in corpus $i$ (likewise for $j$)\n",
    "\n",
    "Here the two corpora are the positive movie reviews (e.g., $i$ = positive) and the negative movie reviews (e.g., $j$ = negative). Using this metric, print out the 25 words most strongly aligned with the positive corpus, and 25 words most strongly aligned with the negative corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logodds_with_uninformative_prior(one_tokens, two_tokens, display=25):\n",
    "    # complete this section\n",
    "    all_tokens = one_tokens + two_tokens\n",
    "    V = set(all_tokens)\n",
    "    # y_w_i\n",
    "    one_tokens_count = dict()\n",
    "    # y_w_j\n",
    "    two_tokens_count = dict()\n",
    "    log_term_one = dict()\n",
    "    log_term_two = dict()\n",
    "    # difference between both log terms\n",
    "    log_diff = dict()\n",
    "    variance = dict()\n",
    "    stdev = dict()\n",
    "    # final score\n",
    "    z_score = dict()\n",
    "    # calculate y_w_i and y_w_j for all words in the vocabulary\n",
    "    for token in V:\n",
    "        one_tokens_count[token] = one_tokens.count(token)\n",
    "        two_tokens_count[token] = two_tokens.count(token)\n",
    "    alpha_w = 0.01\n",
    "    alpha_0 = len(V) * alpha_w\n",
    "    # n_i\n",
    "    one_tokens_size = len(one_tokens)\n",
    "    # n_j\n",
    "    two_tokens_size = len(two_tokens)\n",
    "    for word in V:\n",
    "        log_term_one[word] = math.log((one_tokens_count[word] + alpha_w) / (one_tokens_size + alpha_0 - one_tokens_count[word] - alpha_w))\n",
    "        log_term_two[word] = math.log((two_tokens_count[word] + alpha_w) / (two_tokens_size + alpha_0 - two_tokens_count[word] - alpha_w))\n",
    "        log_diff[word] = log_term_one[word] - log_term_two[word]\n",
    "        # calculate standard deviation\n",
    "        variance[word] = ((1/(one_tokens_count[word] + alpha_w)) + (1/(two_tokens_count[word] + alpha_w)))\n",
    "        stdev[word] = math.sqrt(variance[word])\n",
    "        # final score\n",
    "        z_score[word] = log_diff[word]/stdev[word]\n",
    "    sorted_zscores = sorted(z_score.items(), key=lambda item: item[1])\n",
    "    print(\"words most strongly aligned with negative reviews:\")\n",
    "    for score in sorted_zscores[:display]:\n",
    "        print(score)\n",
    "    print(\"words most strongly aligned with positive reviews:\")\n",
    "    for score in sorted_zscores[-25:]:\n",
    "        print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words most strongly aligned with negative reviews:\n",
      "('bad', -15.874118374895222)\n",
      "('?', -15.035079097668289)\n",
      "(\"n't\", -11.949393783552106)\n",
      "('movie', -10.959996673992299)\n",
      "('worst', -9.92867459130721)\n",
      "('i', -9.448181178355652)\n",
      "('just', -9.122270515824324)\n",
      "('...', -8.675997956464013)\n",
      "('was', -8.617584504048052)\n",
      "('no', -7.999249396143025)\n",
      "('do', -7.521169947814628)\n",
      "('awful', -7.511891984576927)\n",
      "('terrible', -7.446279268276979)\n",
      "('they', -7.372767849274727)\n",
      "('horrible', -7.052577619117426)\n",
      "('why', -7.019505671855516)\n",
      "('this', -6.934937867357723)\n",
      "('poor', -6.930684966472034)\n",
      "('boring', -6.709363182052385)\n",
      "('any', -6.684833313059192)\n",
      "('waste', -6.674077981733288)\n",
      "('script', -6.6612890317425215)\n",
      "('worse', -6.6012235452154595)\n",
      "('have', -6.55152365358799)\n",
      "('stupid', -6.4750566877612865)\n",
      "words most strongly aligned with positive reviews:\n",
      "('loved', 5.0921802161916085)\n",
      "('tony', 5.148053450218753)\n",
      "('most', 5.198384926387417)\n",
      "('beautiful', 5.3556137393424645)\n",
      "('performances', 5.380094126983327)\n",
      "('always', 5.465521212926001)\n",
      "('in', 5.489693080913076)\n",
      "('perfect', 5.547139675935874)\n",
      "('world', 5.664462780541281)\n",
      "('highly', 5.706899505669689)\n",
      "('life', 5.7217812496838585)\n",
      "('of', 5.768768034806312)\n",
      "(',', 5.93698228878491)\n",
      "('performance', 6.052211880700309)\n",
      "('her', 6.38883111352343)\n",
      "('is', 6.559130822066367)\n",
      "('wonderful', 6.697252740688556)\n",
      "('excellent', 7.142854492584097)\n",
      "('war', 7.231860280397061)\n",
      "('love', 7.4664889052138665)\n",
      "('and', 8.008455816960856)\n",
      "('as', 8.068276896558293)\n",
      "('best', 8.221173530354823)\n",
      "('his', 8.444585050679482)\n",
      "('great', 9.607540224421118)\n"
     ]
    }
   ],
   "source": [
    "logodds_with_uninformative_prior(positive_tokens, negative_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: As you increase the constant $\\alpha_w$ in the equations above, what happens to $\\hat\\zeta_w^{(i-j)}$, $\\hat{d}_w^{(i-j)}$ and $\\sigma^2\\left(\\hat{d}_w^{(i-j)}\\right)$ (i.e., do they get bigger or smaller)?  Answer this by plugging the following values in your implementation of these two quantities, and varying $\\alpha_w$ (and, consequently, $\\alpha_0$).\n",
    "\n",
    "* $y_w^i=34$\n",
    "* $y_w^j=17$\n",
    "* $n^i=1000$\n",
    "* $n^j=1000$\n",
    "* $V=500$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Answer: The values seem to be decreasing as a_w is varied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for a_w =  0.01 :\n",
      "stdev:  0.08819206440820998\n",
      "d_w:  0.7102095992733704\n",
      "z_score:  2.3915077005224097 \n",
      "\n",
      "Values for a_w =  0.1 :\n",
      "stdev:  0.08780504536022363\n",
      "d_w:  0.7068143816959451\n",
      "z_score:  2.3853144648767124 \n",
      "\n",
      "Values for a_w =  1 :\n",
      "stdev:  0.08412698412698412\n",
      "d_w:  0.6765135879981137\n",
      "z_score:  2.3324313166697372 \n",
      "\n",
      "Values for a_w =  3 :\n",
      "stdev:  0.07702702702702703\n",
      "d_w:  0.6220640801287232\n",
      "z_score:  2.241370009622216 \n",
      "\n",
      "Values for a_w =  5 :\n",
      "stdev:  0.0710955710955711\n",
      "d_w:  0.5774190440502149\n",
      "z_score:  2.1655580494073816 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def logodds_with_uninformative_prior_Q2(one_tokens, two_tokens):\n",
    "    # complete this section\n",
    "    y_i_w = 34\n",
    "    y_j_w = 17\n",
    "    n_i = 1000\n",
    "    n_j = 1000\n",
    "    V = 500\n",
    "    a_w_list = [0.01, 0.1, 1, 3, 5]\n",
    "    for a_w in a_w_list:\n",
    "        a_0 = V * a_w\n",
    "        log_one = math.log((y_i_w + a_w) / (n_i + a_0 - y_i_w - a_w))\n",
    "        log_two = math.log((y_j_w + a_w) / (n_j + a_0 - y_j_w - a_w))\n",
    "        log_diff = log_one - log_two\n",
    "        stdev = (1/(y_i_w + a_w)) + (1/(y_j_w + a_w))\n",
    "        z_score = log_diff / math.sqrt(stdev)\n",
    "        print(\"Values for a_w = \", a_w,\":\")\n",
    "        print(\"stdev: \",stdev)\n",
    "        print(\"d_w: \", log_diff)\n",
    "        print(\"z_score: \", z_score,\"\\n\")\n",
    "logodds_with_uninformative_prior_Q2(positive_tokens, negative_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make that prior informative by including information about the overall frequency of a given word in a background corpus (i.e., a corpus that represents general word usage, without regard for labeled subcorpora).  To do so, there are only two small changes to make:\n",
    "\n",
    "* We need to gather a background corpus $b$ and calculate $\\hat\\pi_w$, the relative frequency of word $w$ in $b$ (i.e., the number of times $w$ occurs in $b$ divided by the number of words in $b$).\n",
    "\n",
    "* In the uninformative prior above, $\\alpha_w$ was a constant (0.01) and $\\alpha_0 = V * \\alpha_w$.  Let us now set $\\alpha_0 = 1000$ and $\\alpha_w = \\hat\\pi_w * \\alpha_0$.  This reflects a pseudocount capturing the fractional number of times we would expect to see word $w$ in a sample of 1000 words.\n",
    "\n",
    "This allows us to specify that a common word like \"the\" (which has a relative frequency of $\\approx 0.04$) would have $\\alpha_w = 40$, while an infrequent word like \"beneficiaries\" (relative frequency $\\approx 0.00002$) would have $\\alpha_w = 0.02$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Implement a log-odds ratio with informative prior, using a larger background corpus of 5M tokens drawn from the same dataset (given to you as `priors` below, which contains the relative frequencies of words calculated from that corpus) and set $\\alpha_0 = 1000$. Using this metric, print out again the 25 words most strongly aligned with the positive corpus, and 25 words most strongly aligned with the negative corpus.  Is there a meaningful difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_priors(filename):\n",
    "    counts=Counter()\n",
    "    freqs={}\n",
    "    tokens=read_and_tokenize(filename)\n",
    "    total=len(tokens)\n",
    "\n",
    "    for token in tokens:\n",
    "        counts[token]+=1\n",
    "\n",
    "    for word in counts:\n",
    "        freqs[word]=counts[word]/total\n",
    "\n",
    "    return freqs\n",
    "    \n",
    "priors=read_priors(\"../data/sentiment.background.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logodds_with_informative_prior(one_tokens, two_tokens, priors, display=25):\n",
    "    # complete this section\n",
    "    all_tokens = one_tokens + two_tokens\n",
    "    V = set(all_tokens)\n",
    "    one_tokens_count = dict()\n",
    "    two_tokens_count = dict()\n",
    "    log_diff = dict()\n",
    "    variance = dict()\n",
    "    stdev = dict()\n",
    "    log_term_one = dict()\n",
    "    log_term_two = dict()\n",
    "    alpha_w = dict()\n",
    "    z_score = dict()\n",
    "    for token in V:\n",
    "        one_tokens_count[token] = one_tokens.count(token)\n",
    "        two_tokens_count[token] = two_tokens.count(token)\n",
    "    alpha_0 = 1000.0\n",
    "    one_tokens_size = len(one_tokens)\n",
    "    two_tokens_size = len(two_tokens)\n",
    "    #calculate most strongly aligned words with corpus one\n",
    "    #calculate log term\n",
    "    for word in V:\n",
    "        alpha_w[word] = priors[word] * alpha_0\n",
    "        log_term_one[word] = math.log((one_tokens_count[word] + alpha_w[word]) / (one_tokens_size + alpha_0 + one_tokens_count[word] + alpha_w[word]))\n",
    "        log_term_two[word] = math.log((two_tokens_count[word] + alpha_w[word]) / (two_tokens_size + alpha_0 + two_tokens_count[word] + alpha_w[word]))\n",
    "        log_diff[word] = log_term_one[word] - log_term_two[word]\n",
    "        #calculate standard deviation\n",
    "        variance[word] = ((1/(one_tokens_count[word] + alpha_w[word])) + (1/(two_tokens_count[word] + alpha_w[word])))\n",
    "        stdev[word] = math.sqrt(variance[word])\n",
    "        z_score[word] = log_diff[word]/stdev[word]\n",
    "    sorted_zscores = sorted(z_score.items(), key=lambda item: item[1])\n",
    "    print(\"negative:\")\n",
    "    for i in sorted_zscores[:display]:\n",
    "        print(i)\n",
    "    print(\"positive:\")\n",
    "    for i in sorted_zscores[-25:]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative:\n",
      "('bad', -15.81836305010025)\n",
      "('?', -14.947622559858601)\n",
      "(\"n't\", -11.815474486956932)\n",
      "('movie', -10.806524116178911)\n",
      "('worst', -9.953089748636955)\n",
      "('i', -9.196606767018425)\n",
      "('just', -9.06140313065345)\n",
      "('...', -8.632836680955426)\n",
      "('was', -8.475482376722722)\n",
      "('no', -7.957764060198799)\n",
      "('awful', -7.510624608399143)\n",
      "('do', -7.470913986493858)\n",
      "('terrible', -7.447597213269431)\n",
      "('they', -7.312015445148056)\n",
      "('horrible', -7.052757149373359)\n",
      "('why', -6.998125020986118)\n",
      "('poor', -6.919688335083014)\n",
      "('this', -6.774744719676981)\n",
      "('waste', -6.71790227167431)\n",
      "('boring', -6.69886046630574)\n",
      "('any', -6.65932067794369)\n",
      "('script', -6.646104180026674)\n",
      "('worse', -6.594852288437093)\n",
      "('have', -6.486327243629887)\n",
      "('stupid', -6.465921941287761)\n",
      "positive:\n",
      "('loved', 5.08329726141815)\n",
      "('tony', 5.15070412801554)\n",
      "('most', 5.1749359389737855)\n",
      "('in', 5.325752226227236)\n",
      "('beautiful', 5.343549998652135)\n",
      "('performances', 5.369257524450838)\n",
      "(',', 5.448405249802173)\n",
      "('always', 5.451257273749744)\n",
      "('of', 5.508254865540279)\n",
      "('perfect', 5.5378157390733)\n",
      "('world', 5.648943020246218)\n",
      "('life', 5.701034146690215)\n",
      "('highly', 5.70204848795536)\n",
      "('performance', 6.037821691032667)\n",
      "('is', 6.336666027183984)\n",
      "('her', 6.340752279574094)\n",
      "('wonderful', 6.690019311974002)\n",
      "('excellent', 7.132917297392506)\n",
      "('war', 7.222016000500284)\n",
      "('love', 7.440079484895621)\n",
      "('and', 7.611445816715601)\n",
      "('as', 7.94086252986073)\n",
      "('best', 8.19291714830546)\n",
      "('his', 8.356245720100485)\n",
      "('great', 9.567364135154286)\n"
     ]
    }
   ],
   "source": [
    "logodds_with_informative_prior(positive_tokens, negative_tokens, priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
